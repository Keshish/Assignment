{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix \n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = pd.read_csv(\"./pc_X_train.csv\")\n",
        "y = pd.read_csv(\"./pc_Y_train.csv\")\n",
        "\n",
        "y.score= y.score.astype(object)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2,random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Exploration:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(x.shape)\n",
        "print(y.shape)\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "x.head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train_pred = y_train[\"score\"]\n",
        "y_test_pred = y_test[\"score\"]\n",
        "y_train_pred.describe() #basic statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train_pred.value_counts() #the number of different values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Transformation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_trans = Normalizer().fit_transform(x_train)\n",
        "x_trans.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Visualize the distribution of the target variable in the training set\n",
        "sns.countplot(x=\"score\", data=y_train)\n",
        "plt.title(\"Distribution of Scores in Training Set\")\n",
        "plt.show()\n",
        "\n",
        "# Visualize the distribution of the target variable in the testing set\n",
        "sns.countplot(x=\"score\", data=y_test)\n",
        "plt.title(\"Distribution of Scores in Testing Set\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Scaling:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train_pred = y_train[\"score\"].astype(float).values.astype(int)\n",
        "y_test_pred = y_test[\"score\"].astype(float).values.astype(int)\n",
        "\n",
        "lda = LinearDiscriminantAnalysis()\n",
        "lda.fit(x_train_scaled, y_train_pred)\n",
        "print(np.unique(y_train_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Make predictions on the test set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = lda.predict(x_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check unique values\n",
        "print(\"Unique values in y_test_pred:\", np.unique(y_test_pred))\n",
        "print(\"Unique values in y_pred:\", np.unique(y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(\"Missing values in y_test_pred:\", pd.Series(y_test_pred).isnull().sum())\n",
        "print(\"Missing values in y_pred:\", pd.Series(y_pred).isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print a few examples of true and predicted labels\n",
        "for true_label, predicted_label in zip(y_test_pred[:10], y_pred[:10]):\n",
        "    print(f\"True: {true_label}, Predicted: {predicted_label}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Print classification report and confusion matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Classification Report:\\n\", classification_report(y_test_pred, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_pred, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Scaling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_test_scaled = scaler.transform(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train a Linear Regression model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Load training data\n",
        "x_train = pd.read_csv(\"./pc_X_train.csv\")\n",
        "y_train = pd.read_csv(\"./pc_Y_train.csv\")\n",
        "\n",
        "# Convert 'score' column to object type\n",
        "y_train.score = y_train.score.astype(object)\n",
        "\n",
        "# Train-test split\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Extract the 'score' column as the target variable\n",
        "y_train = y_train[\"score\"]\n",
        "y_val = y_val[\"score\"]\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_val_scaled = scaler.transform(x_val)\n",
        "\n",
        "# Model selection and tuning (linear regression in this case)\n",
        "param_grid = {'fit_intercept': [True, False]}\n",
        "regression_model = LinearRegression()\n",
        "grid_search = GridSearchCV(regression_model, param_grid, cv=5)\n",
        "grid_search.fit(x_train_scaled, y_train)\n",
        "\n",
        "# Get the best model from the grid search\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_val_pred = best_model.predict(x_val_scaled)\n",
        "\n",
        "# Calculate RMSE on the validation set\n",
        "rmse_val = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
        "print(\"Root Mean Squared Error on Validation Set:\", rmse_val)\n",
        "\n",
        "# Load the test data\n",
        "x_test = pd.read_csv(\"./pc_X_test.csv\")\n",
        "\n",
        "# Standardize the test features using the same scaler from the training set\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_test_pred = best_model.predict(x_test_scaled)\n",
        "\n",
        "# Save predictions to a CSV file\n",
        "predictions_df = pd.DataFrame({'Id': x_test.index, 'score': y_test_pred})\n",
        "predictions_df.to_csv('pc_y_test_predicted.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Random Forest Regressor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Load training data\n",
        "x_train = pd.read_csv(\"./pc_X_train.csv\")\n",
        "y_train = pd.read_csv(\"./pc_Y_train.csv\")\n",
        "\n",
        "# Convert 'score' column to object type\n",
        "y_train.score = y_train.score.astype(object)\n",
        "\n",
        "# Train-test split\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Extract the 'score' column as the target variable\n",
        "y_train = y_train[\"score\"]\n",
        "y_val = y_val[\"score\"]\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(x_train)\n",
        "x_val_scaled = scaler.transform(x_val)\n",
        "\n",
        "# Model selection and tuning (Random Forest in this case)\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "random_forest_model = RandomForestRegressor(random_state=42)\n",
        "print(\"Before Grid Search\")\n",
        "grid_search = GridSearchCV(random_forest_model, param_grid, cv=5)\n",
        "print(\"Before Fit\")\n",
        "grid_search.fit(x_train_scaled, y_train)\n",
        "print(\"After Fit\")\n",
        "# Get the best model from the grid search\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_val_pred = best_model.predict(x_val_scaled)\n",
        "\n",
        "# Calculate RMSE on the validation set\n",
        "rmse_val = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
        "print(\"Root Mean Squared Error on Validation Set:\", rmse_val)\n",
        "\n",
        "# Load the test data\n",
        "x_test = pd.read_csv(\"./pc_X_test.csv\")\n",
        "\n",
        "# Standardize the test features using the same scaler from the training set\n",
        "x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_test_pred = best_model.predict(x_test_scaled)\n",
        "\n",
        "# Save predictions to a CSV file\n",
        "predictions_df = pd.DataFrame({'Id': x_test.index, 'score': y_test_pred})\n",
        "predictions_df.to_csv('pc_y_test_predicted_rf.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.metrics import *\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import fbeta_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x_train = pd.read_csv(\"./pc_X_train.csv\")\n",
        "y_train = pd.read_csv(\"./pc_Y_train.csv\")\n",
        "df_test = pd.read_csv(\"./pc_X_test.csv\")\n",
        "\n",
        "f3 = make_scorer(fbeta_score, beta=3, average='weighted')\n",
        "\n",
        "# Convert 'score' column to integer type\n",
        "y_train.score = y_train.score.astype(int)\n",
        "\n",
        "\n",
        "# Train-test split\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Extract the 'score' column as the target variable\n",
        "y_train = y_train[\"score\"]\n",
        "y_val = y_val[\"score\"]\n",
        "\n",
        "# Define the pipeline\n",
        "pipeRandFor = Pipeline([\n",
        "    ('imp', SimpleImputer(strategy='median')),\n",
        "    ('pca', PCA(n_components=90, random_state=41)),\n",
        "    ('RandFor', RandomForestClassifier(n_estimators=30, max_depth=9, random_state=41,\n",
        "                                       n_jobs=-1, class_weight='balanced_subsample'))\n",
        "])\n",
        "\n",
        "# Cross-validate\n",
        "cvsRandFor = cross_val_score(pipeRandFor, x_train, y_train, cv=3, scoring=f3, n_jobs=-1)\n",
        "print(cvsRandFor)\n",
        "\n",
        "# Fit the pipeline on the training data\n",
        "pipeRandFor.fit(x_train, y_train)\n",
        "\n",
        "# Predict on the validation data\n",
        "y_pred_RandFor = pipeRandFor.predict(x_val)\n",
        "\n",
        "# Print confusion matrix and fbeta_score on the validation data\n",
        "print(confusion_matrix(y_val, y_pred_RandFor))\n",
        "print(fbeta_score(y_val, y_pred_RandFor, beta=3, average='weighted'))\n",
        "\n",
        "# Assuming 'df_test' is your test data\n",
        "y_pred_RandFor_test = pipeRandFor.predict(df_test)\n",
        "\n",
        "# Save predictions to a CSV file\n",
        "out_RandFor = pd.DataFrame(y_pred_RandFor_test.astype(int))\n",
        "out_RandFor.index = np.arange(0, len(out_RandFor))\n",
        "out_RandFor.to_csv(\"out_RandFor.csv\", header=['score'], index=True, index_label=\"Id\")\n",
        "\n",
        "# Calculate the Root Mean Square Error (RMSE)\n",
        "rmse_RandFor = np.sqrt(mean_squared_error(y_val, y_pred_RandFor))\n",
        "print(f'Root Mean Square Error (RMSE): {rmse_RandFor}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 3078.48706,
      "end_time": "2023-10-28T02:05:11.708868",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-10-28T01:13:53.221808",
      "version": "2.4.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
